{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_songs.csv')\n",
    "df = df.drop(columns=['Unnamed: 0','SName', 'Artist'])\n",
    "df = df.dropna()\n",
    "# Test Removing categories\n",
    "df['Genres'] = df['Genres'].apply(lambda x:  list(set(x.lower().replace(\"/\", \";\").replace(\" \", \"\").split(';'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(df.Genres.values.tolist()).stack().value_counts()\n",
    "def remove_small_genres(row, buffer=5000, counts=counts):\n",
    "    n_list = list()\n",
    "    for r in row:\n",
    "        if counts[r]>buffer:\n",
    "            n_list.append(r)\n",
    "    if len(n_list) == 0:\n",
    "        return np.nan\n",
    "    n_list.sort()\n",
    "    return n_list\n",
    "df['Genres'] = df['Genres'].apply(lambda x:  remove_small_genres(x))\n",
    "df = df.dropna()\n",
    "counts = pd.DataFrame(df.Genres.values.tolist()).stack().value_counts()\n",
    "print(len(df))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add columns of labeled values\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(df.Genres)\n",
    "Y = mlb.transform(df.Genres)\n",
    "\n",
    "for i in range(len(mlb.classes_)):\n",
    "    df.loc[:, [mlb.classes_[i]]] = [y[i] for y in Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "NB_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    NB_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = NB_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NB_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.corpus import stopwords\n",
    "ps = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "test_text = \"Out here in the fields, I fight for my mealsI get my back into my living I don't need to fight to prove I'm right I don't need to be forgiven, yeah, yeah, yeah, yeah, yeah Don't cry, don't raise your eye It's only teenage wasteland Sally, take my hand, we'll travel south 'cross land Put out the fire and don't look past my shoulder The exodus is here, the happy ones are near Let's get together before we get much older Teenage wasteland, it's only teenage wasteland Teenage wasteland, oh, yeah Teenage wasteland They're all wasted\"\n",
    "\n",
    "def clean_lyrics(string):\n",
    "    string = string.lower()\n",
    "    string.replace('chorus','')\n",
    "    string = re.sub(r'[^\\w]', ' ', string)\n",
    "    string = \" \".join([ps.stem(word) for word in string.split() if (len(word) > 3 and word not in stop_words)])\n",
    "    return string\n",
    "\n",
    "test_text = clean_lyrics(test_text)\n",
    "print(NB_pipeline.predict([test_text]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LogReg_pipeline = Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            ('clf', OneVsRestClassifier(LogisticRegression(solver='sag'), n_jobs=1)),\n",
    "        ])\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = LogReg_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "SVC_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "for category in categories:\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    SVC_pipeline.fit(X_train, train[category])\n",
    "    # compute the testing accuracy\n",
    "    prediction = SVC_pipeline.predict(X_test)\n",
    "    print('Test accuracy is {}'.format(accuracy_score(test[category], prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def clf_creator(gram):\n",
    "    gram_vectorizer = CountVectorizer(ngram_range=(1, gram))\n",
    "    gram_vectorizer.fit(df['Lyric'].values)\n",
    "    vectorizered_gram = gram_vectorizer.transform(df['Lyric'].values)\n",
    "    tfidf_vectorizer =  TfidfTransformer()\n",
    "    tfid_vector =  tfidf_vectorizer.fit(vectorizered_gram)\n",
    "    return Pipeline([('vect', gram_vectorizer),\n",
    "                            ('tfIdf', tfid_vector),\n",
    "                          ('clf',BernoulliNB())])\n",
    "\n",
    "\n",
    "unigram_clf = clf_creator(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
